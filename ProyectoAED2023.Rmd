---
title: Proyecto AED
author:
  - name: Inés Esteve Mompó
  - name: Azael
  - name: Manuel
journal: notspecified
type: article
simplesummary: En este proyecto, vamos a analizar el número de préstamos y devoluciones de las bicicletas de 'ValenBisi' durante el año 2022 en cada una de sus estaciones ubicadas por toda la ciudad de Valencia. También compararemos, entre otras cosas, la posible influencia que puede tener, sobre el alquiler de estas bicicletas, estar cerca de otros medios de transporte público de la ciudad como podría ser el ejemplo de 'MetroValencia'.
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: longtable
---


# Introducción. Descripción del proyecto

Vamos a analizar el número de préstamos y devoluciones de las bicicletas de **ValenBisi** durante el año 2022 en cada una de sus estaciones ubicadas por toda la ciudad de Valencia. También compararemos, entre otras cosas, la posible influencia que puede tener, sobre el alquiler de estas bicicletas, estar cerca de otros medios de transporte público de la ciudad como podría ser el ejemplo de 'MetroValencia'.

El trabajo partirá a través de 2 conjuntos de datos, más tarde se podrán incluir otros para hacer futuras comparaciones de nuestros datos. El dataset principal sobre el que trabajaremos, llamado *'ValenBisi_2022.csv'* que podemos encontrar en https://datos.gob.es/es/catalogo/l01462508-valenbisi-2022-alquileres-y-devoluciones, muestra los datos del problema que anteriormente hemos detallado, el número de préstamos y devoluciones de las bicicletas de 'ValenBisi' durante el año 2022. En cambio, el otro dataset que vamos a hacer servir, *'ValenBisi_disponibilidad.csv'*, que podemos encontrar en https://datos.gob.es/es/catalogo/l01462508-valenbisi-disponibilidad y que se actualiza cada 10 minutos, será usado únicamente con la finalidad de recoger la información de dos de sus filas, concretamente aquellas que muestran las coordenadas geográficas de cada una de las estaciones de bicicletas, para el posterior tratamiento de estas.

# Lectura de los primero conjuntos de datos y su interpretación

## Conjunto de datos ValenBisi_2022

Tal como hemos comentado en la introducción, empezamos importando el primer conjunto de datos sobre el que vamos a trabajar, *'ValenBisi_2022.csv'*, que se encuentra en la carpeta 'data' que hemos creado anteriormente dentro de la mista carpeta donde se encuentra este fichero sobre el que estamos escribiendo '.Rmd'.

La lectura la realizamos haciendo uso de la libreria ***'readr'***. Importamos primeramente esta libreria:
```{r}
library(readr)
```

Importamos los datos teniendo en cuenta que el separador es ';':
```{r}
ValenBisi_2022 <- read_delim("data/ValenBisi_2022.csv", 
                    delim = ";", escape_double = FALSE, 
                    col_types = cols(fecha_creacion = col_skip(), 
                    fecha_baja = col_skip()), trim_ws = TRUE)
```

En la primera lectura de los datos hemos eliminado dos de sus columnas ya que estas no aportaban ningún tipo de información a nuestro análisis, estas columnas eran, por una parte, *fecha_creacion*, que correspondía a la fecha en la que se había creado el dataset que analizaremos y, por otra parte, *fecha_baja*, que era una columna llena de valores faltantes 'NA'.

Con la lectura anterior, hemos creado un nuevo data.frame llamado *'ValenBisi_2022'* que contiene nuestros datos organizados en las siguientes columnas:

1.'**id**': columna que contiene el número de observaciones del conjunto de datos, enumeradas desde el 1 hasta el último registro.

2.'**codigo_estación**': columna que designa, a cada estación de Valenbisi, un número concreto como único identificador de la misma.

3.'**estacion**': columna que viene dada por numero de código de estación seguido por el nombre de la ubicación de cada estación concreta escrita en castellano y en un formato concreto donde el separador es '-'.

4.'**tramo_horario**': columna que representa cada hora de un dia.

5.'**numero_de_prestamos**': columna que representa el número de prestamos medios de bicicletas.

6.'**numero_de_devoluciones**': columna que representa el número de devoluciones medias de bicicletas.


Vemos cual es el tipo datos que tiene cada columna, utilizando la función ***'str()'*** que nos proporciona una descripción concisa de la estructura del dataframe:
```{r}
str(ValenBisi_2022)
```
Notamos que los elementos de las columnas '**id**', '**codigo_estacion**','**numero_de_prestamos**' y '**numero_de_devoluciones**' són de tipo numérico y los elementos de las columnas '**estacion**' y '**tramo_horario**' de tipo caracter.


Buscamos posibles valores faltantes(missing values) en las diistintas columnas del data.frame:
```{r}
#Valores faltantes por columnas: vfalt_x_col_1
vfalt_x_col_1 <- sapply(ValenBisi_2022, function(x) sum(is.na(x)))

#Visualización
print(vfalt_x_col_1)
```
Acabamos de probar que no tenemos ningún valor faltante en ninguna de las columnas de nuestro dataframe, por lo que podemos seguir, por ahora, con tranquilidad con nuestro analisis.


Como ya hemos observado, los elementos de '**tramo_horario**' son de tipo 'caracter' pero, realmente queremos que transformarlos a tipo 'factor' para futuros análisis. Lo hacemos a continuación a través de la función '***factor()***':
```{r}
ValenBisi_2022$tramo_horario <- factor(ValenBisi_2022$tramo_horario, ordered=TRUE)
```

Hacemos una comprovacion rápida de que, efectivamente, se ha realizado este cambio de tipo:
```{r}
class(ValenBisi_2022$tramo_horario)
```
Hacemos un a tabla de frecuencia sobre nuestra variable para ver detalladamente cuantos valores hay de cada uno de los niveles presentes en la columna del tramo horario: 
```{r}
table(ValenBisi_2022$tramo_horario)
```
Notamos que los valores son ligeramente diferentes a cada tramo horario, lo que refleja que tendremos algunos casos de estaciones con valores faltantes por lo que respecta a alguna de las horas del dia determinadas.

Por tal de seguir con el análisis de la tabla de frecuencias, comprobamos que valores diferentes puede tomar la columna 'codigo_estacion' con ayuda de la función '***unique()***':
```{r}
unique(ValenBisi_2022$codigo_estacion)
```
Notamos que, pese a que los códigos del 1 al 276 són números consecutivos, hay algunos faltantes sobre los que no tendremos ningún dato, como puede ser el ejemplo de la estación 277, ya que vemos un salto de la estación 276 a la 298. Posteriormente, al realizar el ***'join'*** con el segundo dataset, comentaremos que es lo que ocurre realmente.

Veamos que, efectivamente, el número de elementos de la columna **codigo_estacion*'** no corresponde con el máximo de los códigos que hay en ella, utilizamos las funciones ***length()*** y ***max()*** respectivamente:
```{r}
#Conteo del número de valores únicos en la columna codigo_estacion
length(unique(ValenBisi_2022$codigo_estacion))

#Máximo valor dentro de la columna codigo_estacion
max(ValenBisi_2022$codigo_estacion)
```

Finalmente, hemos comprovado que tenemos datos de 277 estaciones diferentes, por lo que, volviendo al resultado de la tabla de frecuencias, tendremos que tenemos datos de todas las estaciones entre las 6h y las 15h, pero en las otras horas tenemos valores faltantes de alguna de las estaciones.


## Conjunto de datos ValenBisi_disponibilidad

Importamos los datos teniendo en cuenta que el separador es ';':
```{r}
ValenBisi_disponibilidad <- read.csv('./data/ValenBisi_disponibilidad.csv', sep=';')
```

Realmente, tal y como hemos comentado anteriormente, solo nos interesarán 4 de sus columnas: **Direccion**, **Numero**, **geo_shape** y **geo_point_2D**. Vamos a detallar mejor porqué necesitamos cada una de elstas columnas:

-'**Direccion**': columna que nos da información detallada de la ubicación de cada una de las estaciones de biciletas, al igual que hacía la columna '**estacion**' del primer dataframe, pero con la diferencia de que esta parece tener un texto más clarificador que nos puede ayudar a posteriori.

1.'**Numero**': su función es muy importante, ya que nos sirve como enlace directo con el anterior dataframe ya que los valores coinciden en cada una de las estaciones. Tanto esta columna como la de 2.'**codigo_estacion**', utilizan identificadores únicos para cada una de las estaciones, por lo que podemos unir los datos razonando a partir de esta variable.

3.'**geo_shape**': columna escrita en formato JSON que contiene coordenadas geográficas de cada estación donde la clave es "coordinates" y el valor es un array que contiene las coordenadas en el orden [longitud, latitud].

4.'**geo_point_2D**': columna que representa un par de coordenadas geográficas, donde el primer valor es la latitud y el segundo valor es la longitud.


Nos quedamos con las columnas que realmente nos interesan usando el operador tubería ***'%>%'*** junto a ***'select()'*** de la siguiente forma:
```{r}
library(dplyr)

ValenBisi_disponibilidad <- ValenBisi_disponibilidad %>%
                            select(Direccion,Numero,geo_shape, geo_point_2d)
```

Antes de juntar los dos data.frame, vamos a observar también detalladamente este nuevo:
```{r}
str(ValenBisi_disponibilidad)
```
Notamos que las columnas **Direccion**, **geo_shape** y **geo_point_2d** són de tipo 'caracter', en cambio, la columna **Numero**, es de tipo numérico(concretamente tipo 'int').
 
 
Buscamos posibles valores faltantes(missing values) en las distintas columnas del dataframe:
```{r}
#Valores faltantes por columnas: vfalt_x_col_2
vfalt_x_col_2 <- sapply(ValenBisi_disponibilidad, function(x) sum(is.na(x)))

#Visualización
print(vfalt_x_col_2)
```
Acabamos de probar que no tenemos ningún valor faltante en ninguna de las columnas de nuestro dataframe, por lo que podemos seguir con nuestro analisis.


Antes de efectuar la combinación de nuestros dos data.frames, primero vamos a comprovar, como hemos hecho anteriormente con la columna '**codigo_estacion**' del primer dataframe, qué valores diferentes puede tomar la columna '**Numero**' con ayuda de la función ***'unique()'*** y ***'sort()'***, ya que los datos no están ordenados tal como teniamos en el anterior dataframe, en orden ascendente de los valores de '**Numero**':
```{r}
sort(unique(ValenBisi_disponibilidad$Numero))
```
A simple vista podemos observar que no tenemos el último valor que sí aparecía en el anterior dataframe, el que tenia como identificador el número 298. Vamos a comprovar si este es realmente el único identificador faltante.

```{r}
#Conteo del número de valores únicos en la columna codigo_estacion
length(unique(ValenBisi_disponibilidad$Numero))

#Máximo valor dentro de la columna codigo_estacion
max(ValenBisi_disponibilidad$Numero)
```
Notamos, con ayuda de la visualización en tabla, que en este caso si que coinciden el número total de los identificadores con el máximo de los valores de esta columna, por lo que no hay ningún valor faltante, tal como queríamos comprovar.

Volvamos al dataframe *ValenBisi_2022* para observar que valores toma la fila que tiene como identificador o valor en la columna 'codigo_estacion', el número 298:
```{r}
ValenBisi_2022[ValenBisi_2022$codigo_estacion == 298, ]
```
Notamos que tenemos datos desde las 6 horas hasta las 15 horas.

# Combinación de los dos conjuntos de datos

Vamos a  combinar los dos onjuntos de datos tal como hemos ido explicado anteriormente, usaremos ***'left_join()'***:
```{r}
library(dplyr)

ValenBisi <- ValenBisi_2022 %>%
  left_join(ValenBisi_disponibilidad, by = c("codigo_estacion" = "Numero"))
```


Después de la combinación que acabamos de realizar, notamos que podemos haber obtenido posibles valores faltantes(missing values) en las distintas columnas del dataframe, ya que ***'left_join()'*** combina las filas de dos dataframes basándose en una o varias columnas comunes, y conserva todas las filas del dataframe izquierdo, llenando con valores nulos (NA) en las columnas del dataframe derecho cuando no hay coincidencias. Miremos que ha ocurrido:

```{r}
#Valores faltantes por columnas: vfalt_x_col_1
vfalt <- sapply(ValenBisi, function(x) sum(is.na(x)))

#Visualización
print(vfalt)
```

Notamos, tal como esperabamos, la presencia de 9 filas de observaciones faltantes de las columnas **Direccion**, **geo_shape** y **geo_point_2d**, concretamente aquellas que provienen del identificador 298 del que ya hemos hablado. Lo comprobamos filtrando las filas con, al menos, un valor faltante en alguna columna:

```{r}
ValenBisi[!complete.cases(ValenBisi), ]
```
